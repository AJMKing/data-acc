---
- hosts: all
  become: true
  vars:
    pip_install_packages:
      - name: docker
    docker_users:
      - "centos"
    docker_compose_version: "1.22.0"

  roles:
    - geerlingguy.repo-epel
    - geerlingguy.pip
    - geerlingguy.docker

- hosts: all
  become: true
  vars:
      lustre_release: "2.10.4"
  tasks:
    - yum:
        name: git,go,python-virtualenv
        state: present
    - name: Create entries in /etc/hosts for all nodes
      lineinfile:
        path: /etc/hosts
        line: "{{ hostvars[item]['ansible_default_ipv4']['address'] }} {{ item }}.novalocal {{ item }}"
        regexp: "^.* {{ item }}$"
        create: no
        state: present
      with_items:
        - "{{ ansible_play_hosts }}"
    - name: enable lustre server repo
      yum_repository:
        name: lustre-server
        description: lustre-server
        file: lustre-repo
        baseurl: https://downloads.whamcloud.com/public/lustre/lustre-{{ lustre_release }}/el7/patchless-ldiskfs-server
        gpgcheck: no
    - name: enable lustre client repo
      yum_repository:
        name: lustre-client
        description: lustre-client
        file: lustre-repo
        baseurl: https://downloads.whamcloud.com/public/lustre/lustre-{{ lustre_release }}/el7/client
        gpgcheck: no
    - name: enable lustre e2fs repo
      yum_repository:
        name: e2fsprogs-wc
        description: e2fsprogs-wc
        file: lustre-repo
        baseurl: https://downloads.whamcloud.com/public/e2fsprogs/latest/el7
        gpgcheck: no
    - name: Install Lustre Server
      yum:
        name: "lustre-{{ lustre_release }}"
        state: present
    - name: Install Lustre Client
      yum:
        name: "lustre-client-dkms-{{ lustre_release }}"
        state: present

- hosts: all
  tasks:
    - file:
        path: ~/go/github.com/JohnGarbutt/
        state: directory
    - git:
        repo: 'https://github.com/JohnGarbutt/data-acc.git'
        dest: ~/go/src/github.com/JohnGarbutt/data-acc

- hosts: slurm-master[0]
  vars:
      recreate: false
  tasks:
    - docker_service:
        project_src: ~/go/src/github.com/JohnGarbutt/data-acc/ansible/slurm-master
        pull: yes
        state: absent
        remove_volumes: yes
      when: recreate|bool
    - docker_service:
        project_src: ~/go/src/github.com/JohnGarbutt/data-acc/ansible/slurm-master
        pull: yes
      register: output
    - name: ensure slurm cluster registered in db
      shell: |
        sleep 10 && docker exec slurmctld bash -c "/usr/bin/sacctmgr --immediate add cluster name=linux" && docker restart slurmdbd slurmctld
      register: shell_result
      changed_when: "shell_result.rc == 0"
      failed_when: "shell_result.rc != 0 and ('already exists' not in shell_result.stdout)"
      when: output.changed

- hosts: slurm-workers
  vars:
      recreate: false
  tasks:
    - docker_service:
        project_src: ~/go/src/github.com/JohnGarbutt/data-acc/ansible/slurm-worker
        pull: yes
        state: absent
        remove_volumes: yes
      when: recreate|bool
    - docker_service:
        project_src: ~/go/src/github.com/JohnGarbutt/data-acc/ansible/slurm-worker
        pull: yes

- hosts: dac-workers
  vars:
      recreate: false
  tasks:
    - docker_service:
        project_src: ~/go/src/github.com/JohnGarbutt/data-acc/ansible/dac-worker
        pull: yes
        state: absent
        remove_volumes: yes
      when: recreate|bool
    - docker_service:
        project_src: ~/go/src/github.com/JohnGarbutt/data-acc/ansible/dac-worker
        pull: yes
    - name: Add ansible venv
      shell: |
          cd  ~/go/src/github.com/JohnGarbutt/data-acc/fs-ansible/environment
          virtualenv .venv
          source .venv/bin/activate
          pip install -U pip
          pip install -U ansible
      args:
        creates: ~/go/src/github.com/JohnGarbutt/data-acc/fs-ansible/environment/.venv

- hosts: all[0]
  tasks:
    - name: Create ssh key for user
      shell: |
        ssh-keygen -f ~/.ssh/id_rsa -t rsa -N ''
        cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
      args:
         creates: /home/centos/.ssh/id_rsa
    - name: Pull Keys
      synchronize:
        mode: pull
        src:  ~/.ssh/
        dest: /tmp/dac.ssh/
        recursive: yes

- hosts: all
  tasks:
    - name: Push Keys
      synchronize:
        mode: push
        src: /tmp/dac.ssh/
        dest:  ~/.ssh/
        recursive: yes
    - name: trust host keys
      shell: |
        ssh-keyscan -H {{ hostvars[item]['ansible_default_ipv4']['address'] }} >> ~/.ssh/known_hosts
        touch ~/.ssh/.known{{ hostvars[item]['ansible_default_ipv4']['address'] }}
      args:
         creates: "~/.ssh/.known{{ hostvars[item]['ansible_default_ipv4']['address'] }}"
      with_items: "{{ ansible_play_hosts }}"

- hosts: dac-workers
  become: true
  vars:
    nvme_devices:
      - nvme0n1
      - nvme9n1
      - nvme10n1
  tasks:
    - yum:
        name: lvm2
    - name: Create a volume group on top of /dev/vdc
      lvg:
        vg: vg_thin
        pvs: /dev/vdc
    - name: Create a thin pool
      lvol:
        vg: vg_thin
        thinpool: testpool
        size: 190g
    - name: Create a thin volume
      lvol:
        vg: vg_thin
        lv: "{{ item }}"
        thinpool: testpool
        size: 100g
      with_items: "{{ nvme_devices }}"
    - name: Link fake nvme to lvm volume
      file:
        src: "/dev/mapper/vg_thin-{{ item }}"
        dest: "/dev/{{ item }}"
        state: link
      with_items: "{{ nvme_devices }}"
    - name: Ensure lustre present, will require an initial reboot
      modprobe:
        name: lustre
        state: present

- hosts: dac-workers
  become: true
  vars:
    nvme_devices:
        nvme1n1: "/dev/vdd"
        nvme2n1: "/dev/vde"
        nvme3n1: "/dev/vdf"
        nvme4n1: "/dev/vdg"
  tasks:
    - name: create nvme symlinks
      file:
        src: "{{ item.value }}"
        dest: "/dev/{{ item.key }}"
        state: link
      with_dict: "{{ nvme_devices }}"
